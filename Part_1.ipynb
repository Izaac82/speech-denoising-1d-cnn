{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 - Speech Denoising Using 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "\n",
    "# Reading the training file\n",
    "s, sr=librosa.load('data/train_clean_male.wav', sr=None) \n",
    "S_input=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "\n",
    "sn, sr=librosa.load('data/train_dirty_male.wav', sr=None) \n",
    "X_input=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "\n",
    "# Reading test 01 file\n",
    "st_01, sr_01=librosa.load('data/test_x_01.wav', sr=None) \n",
    "X_test_01=librosa.stft(st_01, n_fft=1024, hop_length=512)\n",
    "\n",
    "# Reading test 02 file\n",
    "st_02, sr_02=librosa.load('data/test_x_02.wav', sr=None) \n",
    "X_test_02=librosa.stft(st_02, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the magnitudes of training set, and test sets\n",
    "S_mag = np.abs(S_input).T\n",
    "X_mag = np.abs(X_input).T\n",
    "X_test_01_mag = np.abs(X_test_01).T\n",
    "X_test_02_mag = np.abs(X_test_02).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean training audio shape (S_mag):  (2459, 513)\n",
      "Noisy training audio shape (X_mag):  (2459, 513)\n",
      "First test audio shape (X_test_01_mag):  (142, 513)\n",
      "Second test audio shape (X_test_02_mag):  (380, 513)\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean training audio shape (S_mag): \",S_mag.shape)\n",
    "print(\"Noisy training audio shape (X_mag): \",X_mag.shape)\n",
    "print(\"First test audio shape (X_test_01_mag): \",X_test_01_mag.shape)\n",
    "print(\"Second test audio shape (X_test_02_mag): \",X_test_02_mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean training audio shape (S_mag):  (2459, 513)\n",
      "Noisy training audio shape (X_mag):  (2459, 513, 1)\n",
      "First test audio shape (X_test_01_mag):  (142, 513, 1)\n",
      "Second test audio shape (X_test_02_mag):  (380, 513, 1)\n"
     ]
    }
   ],
   "source": [
    "from numpy import newaxis\n",
    "\n",
    "X_mag_ = X_mag[..., newaxis]\n",
    "X_test_01_mag_ = X_test_01_mag[..., newaxis]\n",
    "X_test_02_mag_ = X_test_02_mag[..., newaxis]\n",
    "\n",
    "print(\"Clean training audio shape (S_mag): \",S_mag.shape)\n",
    "print(\"Noisy training audio shape (X_mag): \",X_mag_.shape)\n",
    "print(\"First test audio shape (X_test_01_mag): \",X_test_01_mag_.shape)\n",
    "print(\"Second test audio shape (X_test_02_mag): \",X_test_02_mag_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr(dirty, clean):\n",
    "    return round(10 * np.log10(np.sum(np.square(clean))/np.sum(np.square(clean - dirty))),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\utkar\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create placeholders - convention used - [batch_size, width, num_channels]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 513, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 513])\n",
    "\n",
    "# Create filters - [width, num_channels_in, num_channels_out]\n",
    "W1 = tf.get_variable(\"W1\", [3,1,32], initializer=tf.keras.initializers.he_normal(seed=0))\n",
    "W2 = tf.get_variable(\"W2\", [3,32,32], initializer=tf.keras.initializers.he_normal(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-4c596fb42c22>:7: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling1D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FA9518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FA9518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FA9518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FA9518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FE1A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FE1A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FE1A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling1D.call of <tensorflow.python.layers.pooling.MaxPooling1D object at 0x000001C0A0FE1A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001C0A1031C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001C0A1031C50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001C0A1031C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001C0A1031C50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1031C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1031C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1031C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1031C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1012518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1012518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1012518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001C0A1012518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\utkar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.00006\n",
    "\n",
    "# First Convolution Network using stride 1 and padding as VALID (this was done to reduce size as it was taking a long time and gave better result)\n",
    "Z1 = tf.nn.conv1d(X, W1, stride = 1, padding = 'VALID')\n",
    "A1 = tf.nn.relu(Z1)\n",
    "# Maxpooling layer with pool_size 4 and stride 1, padding is valid\n",
    "P1 = tf.layers.max_pooling1d(A1, pool_size=4, strides=1, padding='VALID')\n",
    "\n",
    "# Second Convolution Network with stride 1 and padding as VALID\n",
    "Z2 = tf.nn.conv1d(P1, W2, stride = 1, padding = 'VALID')\n",
    "A2 = tf.nn.relu(Z2)\n",
    "# Maxpooling layer with pool_size 2 and stride 2, padding is VALID\n",
    "P2 = tf.layers.max_pooling1d(A2, pool_size=2, strides=2, padding='VALID')\n",
    "\n",
    "# Flatten the layers \n",
    "P3 = tf.contrib.layers.flatten(P2)\n",
    "\n",
    "# Fully-connected layers with RELU activation and He initialization\n",
    "Z3 = tf.contrib.layers.fully_connected(P3, 1024, activation_fn=tf.nn.relu, weights_initializer=tf.keras.initializers.he_normal())\n",
    "Z4 = tf.contrib.layers.fully_connected(Z3, 513, activation_fn=tf.nn.relu, weights_initializer=tf.keras.initializers.he_normal())\n",
    "\n",
    "# Loss function - mean squared error\n",
    "cost = tf.losses.mean_squared_error(predictions = Z4, labels = Y)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=alpha).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel Summary:\n",
      "\u001b[0m\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "W1:0 (float32_ref 3x1x32) [96, bytes: 384]\n",
      "W2:0 (float32_ref 3x32x32) [3072, bytes: 12288]\n",
      "fully_connected/weights:0 (float32_ref 8096x1024) [8290304, bytes: 33161216]\n",
      "fully_connected/biases:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "fully_connected_1/weights:0 (float32_ref 1024x513) [525312, bytes: 2101248]\n",
      "fully_connected_1/biases:0 (float32_ref 513) [513, bytes: 2052]\n",
      "Total size of variables: 8820321\n",
      "Total bytes of variables: 35281284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8820321, 35281284)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "print('\\033[1m' + \"Model Summary:\\n\" + '\\033[0m')\n",
    "model_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(model_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples :  2459\n",
      "Number of Epochs :  500\n",
      "Number of batches :  24\n",
      "Epoch :  0 \tCost :  0.15525713500877222\n",
      "Epoch :  50 \tCost :  0.011535281897522509\n",
      "Epoch :  100 \tCost :  0.008847963753699636\n",
      "Epoch :  150 \tCost :  0.0064324035386865335\n",
      "Epoch :  200 \tCost :  0.005451753987775494\n",
      "Epoch :  250 \tCost :  0.004389559631817974\n",
      "Epoch :  300 \tCost :  0.0031120403630969426\n",
      "Epoch :  350 \tCost :  0.0027580466072928784\n",
      "Epoch :  400 \tCost :  0.001949995409328646\n",
      "Epoch :  450 \tCost :  0.0018564730368476983\n",
      "Epoch :  499 \tCost :  0.0017147543937123069\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "    # Run the initialization\n",
    "    sess.run(init)\n",
    "        \n",
    "    m = len(X_mag_)\n",
    "    num_batches = int(m/batch_size)\n",
    "    \n",
    "    print(\"Number of training samples : \", m)\n",
    "    print(\"Number of Epochs : \", epochs)\n",
    "    print(\"Number of batches : \", num_batches)\n",
    "    \n",
    "    epoch_loss_ = []\n",
    "    \n",
    "    snr_list = []\n",
    "    snr_list2 = []\n",
    "    \n",
    "    # iterate through epochs\n",
    "    for epoch in range(epochs):\n",
    "        cost_ = 0.0\n",
    "        \n",
    "        # iterate through \n",
    "        i = 0\n",
    "        j = batch_size + 1\n",
    "        for batch in range(num_batches):\n",
    "            X_batch = X_mag_[i:j]\n",
    "            Y_batch = S_mag[i:j]\n",
    "            \n",
    "            i = j\n",
    "            j = j + batch_size\n",
    "            \n",
    "            _,curr_cost = sess.run([optimizer, cost], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            \n",
    "            cost_ = cost_ + curr_cost/num_batches\n",
    "            \n",
    "            y_hat_train = sess.run(Z4, feed_dict={X:X_mag_})\n",
    "            y_hat_test_02 = sess.run(Z4, feed_dict={X:X_test_02_mag_})\n",
    "            y_hat_test_01 = sess.run(Z4, feed_dict={X:X_test_01_mag_})\n",
    "        \n",
    "        snr_list.append(snr(X_mag,y_hat_train))       \n",
    "        snr_list2.append(snr(X_test_02_mag,y_hat_test_02))\n",
    "        \n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch : \", epoch, \"\\tCost : \", cost_)\n",
    "    print(\"Epoch : \", epoch, \"\\tCost : \", cost_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSignal to Noise Ratios:\n",
      "\u001b[0m\n",
      "SNR for the original cleaned audio sample (training) and the output of DNN for the training sample. \n",
      "SNR of train_clean_male and y_hat : 16.91668\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' + \"Signal to Noise Ratios:\\n\" + '\\033[0m')\n",
    "print(\"SNR for the original cleaned audio sample (training) and the output of DNN for the training sample. \")\n",
    "print(\"SNR of train_clean_male and y_hat :\", snr(y_hat_train,S_mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the outputs to files \n",
    "\n",
    "# Recover the (complex-valued) speech spectrogram of the test signal \n",
    "s_01 = np.multiply(np.divide(X_test_01,X_test_01_mag.T),y_hat_test_01.T)\n",
    "s_02 = np.multiply(np.divide(X_test_02,X_test_02_mag.T),y_hat_test_02.T)\n",
    "\n",
    "# Take inverse-STFT \n",
    "out_01 = librosa.istft(s_01, hop_length=512)\n",
    "out_02 = librosa.istft(s_02, hop_length=512)\n",
    "\n",
    "# Write the output\n",
    "librosa.output.write_wav('output1/test_s_01_recons.wav', out_01, sr_01)\n",
    "librosa.output.write_wav('output1/test_s_02_recons.wav', out_02, sr_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
